# Copyright 2020 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================


# TODO: Update everything and remove unnecesary config.

# Configuration for running the complete pipeline including modeling and evaluation.

# Absolute paths to non-code resources.
file_paths:
  queries: "/home/jupyter/github_msba_capstone/msba-capstone-2020/queries"
  automl_service_account_key: "/home/jupyter/.oauth_keys/automl_service_account_key.json"

# Global config used by multiple pipelie steps. Also made available
# as parameters to all SQL queries.
global:
  # Project and dataset configuration.
  source_project_id: "bigquery-public-data"
  destination_project_id: "ut-goog"
  source_dataset: "cfpb_complaints"
  destination_dataset: "cfpb_complaints"

  # Clean data, minor refined versions of provided data.
  source_table: "complaint_database"
  nlp_features_table: "complaints_nlp"
  cleaned_features_table: "complaints_clean_categories"
  nulls_removed_table: "complaints_nulls_removed"
  clean_table: "complaints_clean"
  # TODO: Add the NLP API table
  
  # Split features into training and prediction.
  features_train_table: "FeaturesTrain"
  features_predict_table: "FeaturesPredict"

  # Output tables for predictions and failed predictions from the batch
  # prediction job, ex. numeric column recieved a string.
  predictions_table: "Predictions"
  failed_predictions_table: "FailedPredictions"
  
  # Evaluation
  eval_table: "Evaluation"
  eval_metrics_table: "EvaluationMetrics"

  # AutoML Parameters. It is assumed that no other datasets or models have
  # been created with these names, or the pipeline will fail. They can be
  # deleted using the client, or the UI.
  dataset_display_name: "CFPBDataset"
  model_display_name: "CFPBModel"
  automl_compute_region: "us-central1"

  # Final model will be trained on test data, metrics are currently based
  # on the predict split instead. AutoML Requires at least one row of test data,

# Files with templated queries, in file_paths.queries.
query_files:
  remove_nulls: "remove_nulls.sql"
  clean_categories: "clean_categories.sql"
  # TODO: Query for NLP API features 
  combine_tables: "combine_tables.sql"
  train_eval_split: "train_test_split.sql"
  # Probably a calculation of some domain-specific eval?
  # eval: "eval.sql"

# Parameters specific to individual SQL pipeline steps.
query_params:

  removing_nulls:
    column1: "consumer_complaint_narrative"
    column2: "company_response_to_consumer"
    
  category_cleanup:
    old_issue1: "Dealing with your lender or servicer"
    old_issue2: "Dealing with my lender or servicer"
    new_issue1: "Other"
    new_issue2: "Dealing with lender or servicer"
    old_subprod1: "Other (i.e. phone, health club, etc.)"
    old_subprod2: "Loan"
    new_subprod1: "Other"
    new_subprod2: "Other Loan"
    old_subissue1: "Debt is not yours"
    old_subissue2: "Debt is not mine"
    old_subissue3: "Account status"
    new_subissue1: "Other"
    new_subissue2: "Incorrect debt"
    new_subissue3: "Account status incorrect"
    
  train_test_split:
    test_threshold: 0.2
      

# Training parameters for the model.
model:
  # See https://cloud.google.com/automl-tables/docs/train for more details
  # Training objective and maximum train time, early stopping is enabled.
  train_budget_hours: 1
  optimization_objective: "MINIMIZE_LOG_LOSS"
  
  # See https://cloud.google.com/automl-tables/docs/prepare for more details on
  # the target and split columns.
  # Target column to predict
  target_column: "company_response_to_consumer"
  # Split dataset into training, validation, and test.
  split_column: "splitting"

  # Columns in dataset to exclude from training, will still appear in prediction.
  # Target (model.target_column), Split (model.split_column), Weight (unused),
  # and Key column (defined below in columns) must be in the
  # exclude_columns list or create_model will raise an exception.
  exclude_columns:
    - "complaint_id"
    - "date_received"
    - "company_public_response"
    - "company_name"
    - "tags"
    - "company_response_to_consumer"
    - "consumer_consent_provided"
    - "date_sent_to_company"
    - "timely_response"
    - "consumer_disputed"
    - "splitting"

  # Define the data type, nullability, and forecasting type for every column.
  # Values for type_code: "CATEGORY", "STRING", "FLOAT64", "TIMESTAMP".
  columns:

    "product":
      type_code: "CATEGORY"
      nullable: TRUE

    "subproduct":
      type_code: "CATEGORY"
      nullable: TRUE

    "issue":
      type_code: "CATEGORY"
      nullable: TRUE

    "subissue":
      type_code: "CATEGORY"
      nullable: TRUE

    "consumer_complaint_narrative":
      type_code: "STRING"
      nullable: FALSE

    "state":
      type_code: "CATEGORY"
      nullable: TRUE

    "zip_code":
      type_code: "CATEGORY"
      nullable: TRUE

    "complaint_id":
      type_code: "FLOAT64"
      nullable: FALSE

#     "date_received":
#       type_code: "TIMESTAMP"
#       nullable: FALSE

    "company_public_response":
      type_code: "CATEGORY"
      nullable: TRUE

    "company_name":
      type_code: "CATEGORY"
      nullable: TRUE

    "tags":
      type_code: "CATEGORY"
      nullable: TRUE

    "consumer_consent_provided":
      type_code: "CATEGORY"
      nullable: TRUE

    "submitted_via":
      type_code: "CATEGORY"
      nullable: TRUE

#     "date_sent_to_company":
#       type_code: "TIMESTAMP"
#       nullable: FALSE

    "company_response_to_consumer":
      type_code: "CATEGORY"
      nullable: FALSE

    "timely_response":
      type_code: "CATEGORY"
      nullable: TRUE

    "consumer_disputed":
      type_code: "CATEGORY"
      nullable: TRUE

    "splitting":
      type_code: "CATEGORY"
      nullable: FALSE